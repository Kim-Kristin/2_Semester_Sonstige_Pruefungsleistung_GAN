{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wasserstein GAN\n",
    "Vorteile:\n",
    "    - bessere Traings-Stabilität als DCGAN\n",
    "    -\n",
    "Nachteile:\n",
    "    - Längeres training\n",
    "\n",
    " Idee beim GAN:\n",
    "    - Distanz zwischen prob generate und prob realistic soll so klein\n",
    "    wie möglich sein, um möglichst realistische Bilder zu generieren\n",
    "\n",
    "Problem:\n",
    "    - Wie wird die Distanz zwischen den beiden prob Distributionen\n",
    "    beschrieben/ definiert\n",
    "\n",
    "Lösung:\n",
    "    - Wasserstein Distance -> WGAN nutzt Wasserstein Distance für den Loss\n",
    "    (- Kullback-Leiber (KL) divergence)\n",
    "    (- Jensen-Shannon (JS) divergence) <- Equivalent zum GAN Loss\n",
    "        -> Hat Gradienten Probleme die das Training instabil werden lassen\n",
    "\n",
    "WGAN:\n",
    "    - Disc. Maximierung von Expression\n",
    "    - Gen.  Minimierung von Expression\n",
    "\n",
    "Default- Werte im WGAN\n",
    "    - LR = 0.00005\n",
    "    - Clipping Parameter = 0.01\n",
    "    - Batch Size = 64\n",
    "    - n_critic = 5 (Anzahl der Iterationen von critic pro generation iteration)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9b614",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # Loss\n",
    "from torchvision.utils import save_image  # Speichern von Bildern\n",
    "import torch.optim as optim  # Optimierungs-Algorithmen\n",
    "import torch.nn as nn  # Neuronales Netz\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt  # plotten von Grafen/ Bildern\n",
    "import torchvision.transforms as transforms  # Transformieren von Bildern\n",
    "import torchvision.datasets as ImageFolder\n",
    "import torch.utils.data as DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import os                 # Dient zum lokalen Speichern des Datasets\n",
    "import opendatasets as od\n",
    "from random import weibullvariate\n",
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fec439",
   "metadata": {},
   "source": [
    "Pakete importieren\n",
    "Import Pakete\n",
    "Dient zum Laden des Dataset aus opensource-Quellen (z.B. Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5717a69",
   "metadata": {},
   "source": [
    "Definieren von Parametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3a637",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64  # Größe der Bilder\n",
    "BATCH_SIZE = 64  # Anzahl der Batches\n",
    "WORKERS = 2  # Anzahl der Kerne beim Arbeiten auf der GPU\n",
    "# Normalisierung mit 0.5 Mittelwert und Standardabweichung für alle drei Channels der Bilder\n",
    "NORM = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "NUM_EPOCH = 20  # Anzahl der Epochen\n",
    "LR = 0.00005  # Learningrate\n",
    "LATENT_SIZE = 100  # Radom Input für den Generator\n",
    "N_CRTIC = 5\n",
    "WEIGHT_CLIPPING = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee44375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jovian.ai/ahmadyahya11/pytorch-gans-anime\n",
    "# Ordner für den Download anlegen\n",
    "data_dir = '../data/'\n",
    "os.makedirs(data_dir, exist_ok=True)  # Anlegen eines Ordners für Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung zum Umgang mit Opendata und Kaggle - https://pypi.org/project/opendatasets/\n",
    "# Datensatz:Anime-Faces werden von Kaggle geladen\n",
    "# Hierfür wird der User-API-KEY benötigt\n",
    "# APIKEY {\"username\":\"kimmhl\",\"key\":\"f585163b4ee30f0a5b44b1a902dc56e6\"}\n",
    "dataset_url = 'https://www.kaggle.com/splcher/animefacedataset'\n",
    "# Images werden in './animefacedataset' gespeichert\n",
    "od.download(dataset_url, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ausgabe zu den Ordnern\n",
    "\"\"\"\n",
    "print(os.listdir(data_dir))  # zeigt Ordner an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426061eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt 10 Bezeichnungen von Bildern aus\n",
    "print(os.listdir(data_dir+'animefacedataset/images')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d956ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "transform = transforms.Compose([\n",
    "    # Resize der Images auf 64 der kürzesten Seite; Andere Seite wird\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    # skaliert, um das Seitenverhältnis des Bildes beizubehalten.\n",
    "    # Zuschneiden auf die Mitte des Images, sodass ein quadratisches Bild mit 64 x 64 Pixeln entsteht\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    # Umwandeln in einen Tensor (Bildern in numerische Werte umwandeln)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*NORM)])          # Normalisierung Mean & Standardabweichung von 0.5 für alle Channels\n",
    "# (Anzahl: 3 für farbige Bilder)\n",
    "# Pixelwerte liegen damit zwischen (-1;1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffc1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\"\"\"\n",
    "ImageFolder() : Befehl erwartet, dass nach Images nach labeln organisiert sind (root/label/picture.png)\n",
    "\"\"\"\n",
    "org_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\"\"\"\n",
    "Dataloader(): ermöglicht zufällige Stichproben der Daten auszugeben;\n",
    "Dient dazu, dass das Modell nicht mit dem gesamten Dataset umgehen muss > Training effizienter\n",
    "\"\"\"\n",
    "org_loader = t.utils.data.DataLoader(org_dataset,              # Dataset (Images)\n",
    "                                     # Es wird auf Batches trainiert, damit auf Basis eines Batch-Fehlers das NN angepasst wird\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18f8a7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Nutzen der GPU wenn vorhanden, ansonsten CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if t.cuda.is_available():     # Wenn cuda verfügbar dann:\n",
    "        return t.device('cuda')   # Nutze Device = Cuda (=GPU)\n",
    "    else:                         # Ansonsten\n",
    "        return t.device('cpu')    # Nutze Device = CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10014ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen welches Device verfügbar ist\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48987c13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Hilfsklasse zum Verschieben des Dataloaders \"org_loader\" auf das jeweilige Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aa58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "\n",
    "    # Initialisierung\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    # Anzahl der Images pro Batch\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "    # Erstellt einen Batch an Tensoren nach dem Verschieben auf das Device\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(tensor.to(self.device) for tensor in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea300703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader auf dem verfügbaren Device\n",
    "org_loader = DeviceDataLoader(org_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60526912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Generator 1 Input Layer; 3 Hidden Layer ; 1 Output Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            # Output = (inputsize - 1)*stride - 2*padding + (kernelsite-1)+1\n",
    "            # ConvTranspose2d hilft dabei aus einem kleinen\n",
    "            nn.ConvTranspose2d(LATENT_SIZE, IMAGE_SIZE*8, 4, 1, 0, bias=False),\n",
    "            # Tensor einen größeren Tensor zu erstellen (Bezogen auf Channels)\n",
    "            nn.BatchNorm2d(IMAGE_SIZE*8),\n",
    "            nn.ReLU(inplace=True),  # Relu lässt keine negativen werte zu\n",
    "\n",
    "            nn.ConvTranspose2d(IMAGE_SIZE*8, IMAGE_SIZE * \\\n",
    "                               4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(IMAGE_SIZE*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(IMAGE_SIZE*4, IMAGE_SIZE * \\\n",
    "                               2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(IMAGE_SIZE*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(IMAGE_SIZE*2, IMAGE_SIZE, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(IMAGE_SIZE),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(IMAGE_SIZE, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()  # (-1 und 1) ; Tanh wird häufig verwendet da eine begrenzte Aktivierung es dem Modell ermöglicht,\n",
    "            # schneller zu lernen. (https://arxiv.org/pdf/1511.06434.pdf S. 3)\n",
    "\n",
    "            # Output: 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    # Feedforward\n",
    "    def forward(self, input):\n",
    "        output = self.generator(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Generators\n",
    "NN_Generator = Generator().to(device)\n",
    "print(NN_Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22685ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator (t.nn.Module):\n",
    "    \"\"\"\n",
    "    Diskriminator 1 Input Layer; 3 Hidden Layer ; 1 Output Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            # Output = ((inputsize) + 2*padding + (kernelsite-1)-1/stride) -1\n",
    "            # conv2d hilft dabei aus einem großem Tensor einen kleinen Tensor zu stellen\n",
    "            nn.Conv2d(3, IMAGE_SIZE, 4, 2, 1, bias=False),\n",
    "            # Leaky RELU lässt negative Werte zu (nicht wie RELU); Neuronen werden somit nicht auf Null gesetzt\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hilft dem Generator, da dieser nur \"Lernen\" kann wenn er vom Diskriminator einen Gradienten erhält\n",
    "\n",
    "            # state size. (IMAGE_SIZE) x 32 x 32\n",
    "            nn.Conv2d(IMAGE_SIZE, IMAGE_SIZE * 2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(IMAGE_SIZE * 2, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (IMAGE_SIZE*2) x 16 x 16\n",
    "            nn.Conv2d(IMAGE_SIZE * 2, IMAGE_SIZE * 4, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(IMAGE_SIZE * 4, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.Dropout2d(0.1),  #Dropout\n",
    "\n",
    "            # state size. (IMAGE_SIZE*4) x 8 x 8\n",
    "            nn.Conv2d(IMAGE_SIZE * 4, IMAGE_SIZE * 8, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(IMAGE_SIZE * 8, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            # state size. (IMAGE_SIZE*8) x 4 x 4\n",
    "            nn.Conv2d(IMAGE_SIZE * 8, 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        # Sigmoid Aktivierungsfunktion\n",
    "        # nn.Sigmoid())  # (Werte zwischen 0 und 1); Sigmoid wird verwendet, um zu erkenen wie weit die generierten Bilder von den orginalen abweichen\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.discriminator(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2df960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Diskriminators\n",
    "NN_Discriminator = Discriminator().to(device)\n",
    "print(NN_Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Normalisierng von Tensoren und grafischen Darstellung\n",
    "def tensor_norm(img_tensors):\n",
    "    # print (img_tensors)\n",
    "    # print (img_tensors * NORM [1][0] + NORM [0][0])\n",
    "    return img_tensors * NORM[1][0] + NORM[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.title(\"Fake_Images\")\n",
    "    ax.imshow(make_grid(tensor_norm(images.detach()[:nmax]), nrow=8).permute(\n",
    "        1, 2, 0).cpu())  # detach() : erstellt eine neue \"Ansicht\",\n",
    "    # sodass diese Operationen nicht mehr verfolgt werden,\n",
    "    # d. h. der Gradient wird nicht berechnet und der Untergraph\n",
    "    # wird nicht aufgezeichnet > Speicher wird nicht verwendet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992eff0",
   "metadata": {},
   "source": [
    "Radom Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6412cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator --> Input: Random Tensor\n",
    "# Generator --> Output: Fake-Images (Batchsize, data_dim, Pixel, Pixel)\n",
    "random_Tensor = t.randn(BATCH_SIZE, LATENT_SIZE, 1, 1, device=device)\n",
    "fake_images = NN_Generator(random_Tensor)\n",
    "print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fce74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(fake_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03872a4",
   "metadata": {},
   "source": [
    "Trainieren des Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb90a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train(Gen_Opt):\n",
    "\n",
    "    #Gradienten = 0\n",
    "    Gen_Opt.zero_grad()\n",
    "\n",
    "    # Generierung von Fake-Images\n",
    "    fake_img = NN_Generator(random_Tensor)\n",
    "\n",
    "    # Übergeben der Fakes-Images an den Diskriminator (Versuch den Diskriminator zu täuschen)\n",
    "    pred = NN_Discriminator(fake_img)\n",
    "    # Torch.ones gibt einen tensor zurück welcher nur den Wert 1 enthält, und dem Shape Size = BATCH_SIZE\n",
    "    #target = t.ones(BATCH_SIZE, 1, device=device)\n",
    "    # loss = F.binary_cross_entropy(pred, target)  # loss_func(pred, target)\n",
    "\n",
    "    loss = -t.mean(pred)\n",
    "\n",
    "    loss.backward()\n",
    "    Gen_Opt.step()\n",
    "\n",
    "    # Backprop./ Update der Gewichte des Generators\n",
    "    # loss.backward()\n",
    "    # Gen_Opt.step()\n",
    "\n",
    "    #print(\"Training Gen\")\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ece856",
   "metadata": {},
   "source": [
    "Trainieren des Diskriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c845fc",
   "metadata": {
    "comment_questions": false
   },
   "outputs": [],
   "source": [
    "def disc_train(real_images, Dis_Opt):\n",
    "\n",
    "    #Gradienten = 0\n",
    "    Dis_Opt.zero_grad()\n",
    "\n",
    "    # ????\n",
    "    #data = real_images.to(device)\n",
    "    #cur_batch_size = data.shape[0]\n",
    "    #noise = t.randn(cur_batch_size, 128, 1, 1).to(device)\n",
    "\n",
    "    fake = NN_Generator(random_Tensor).to(device)\n",
    "\n",
    "    # Reale Bilder werden an den Diskriminator übergeben\n",
    "    pred_real = NN_Discriminator(real_images)\n",
    "    # print(pred_real.size())\n",
    "\n",
    "    # Kennzeichnen der realen Bilder mit 1\n",
    "    #target_real = t.ones(real_images.size(0), 1, device=device)\n",
    "    # print(target_real.size())\n",
    "\n",
    "    # Berechnung des Losses mit realen Bildern\n",
    "    #loss_real = F.binary_cross_entropy(pred_real, target_real)\n",
    "    #real_score = t.mean(pred_real).item()\n",
    "\n",
    "    \"\"\"\n",
    "    2 Erstellen von Fake_Bildern\n",
    "    \"\"\"\n",
    "    # Generierung von Fakeimages\n",
    "    #fake_img = NN_Generator(random_Tensor).to(device)\n",
    "\n",
    "    \"\"\"\n",
    "    3 Trainieren des Diskriminators auf den erstellten Fake_Bildern\n",
    "    \"\"\"\n",
    "    # Fake Bilder werden an den Diskriminator übergeben\n",
    "    pred_fake = NN_Discriminator(fake).to(device)\n",
    "\n",
    "    # Kennzeichnen der Fake-Bilder mit 0\n",
    "    #target_fake = t.zeros(fake_img.size(0), 1, device=device)\n",
    "\n",
    "    # Loss Function - Fehler des Fake-Batch wird berechnet\n",
    "    #loss_fake = F.binary_cross_entropy(pred_fake, target_fake)\n",
    "    #fake_score = t.mean(pred_fake).item()\n",
    "\n",
    "    # Berechnung des Gesamt-Loss von realen und fake Images\n",
    "    #loss_sum = loss_real + loss_fake\n",
    "\n",
    "    loss_critic = -(t.mean(pred_real)-t.mean(pred_fake))\n",
    "\n",
    "    loss_critic.backward(retain_graph=True)\n",
    "\n",
    "    Dis_Opt.step()\n",
    "\n",
    "    #print(\"Training disc\")\n",
    "    return loss_critic.item()  # real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ordner anlegen für die vom Generator erstellten Images\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_gen_samples = '../data/outputs/'\n",
    "#os.makedirs('../outputs/dir_gen_samples', exist_ok=True)\n",
    "os.makedirs(dir_gen_samples, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53528a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zum Speichern der generierten Bilder\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965683e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saves_gen_samples(idx, random_Tensor):\n",
    "    # Randomisierter Tensor wird an den Generator übergeben\n",
    "    fake_img = NN_Generator(random_Tensor)\n",
    "    # Setzen von Bildbezeichnungen für die Fake_Images\n",
    "    fake_img_name = \"gen_img-{0:0=4d}.png\".format(idx)\n",
    "    # Tensor-Normalisierung; Speichern der Fake_Images im Ordner \"Outputs/dir_gen_samples/\"\n",
    "    save_image(tensor_norm(fake_img), os.path.join(\n",
    "        dir_gen_samples, fake_img_name), nrow=8)\n",
    "    show_images(fake_img)  # Plotten der Fake_Images\n",
    "    print(\"Gespeichert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufruf der Funktion\n",
    "saves_gen_samples(0, random_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Zentrale Trainings-Funktion\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7feabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(NN_Discriminator, NN_Generator, NUM_EPOCH, LR, start_idx=1):\n",
    "    t.cuda.empty_cache()  # leert den Cache, wenn auf der GPU gearbeitet wird\n",
    "\n",
    "    NN_Discriminator.train()\n",
    "    NN_Generator.train()\n",
    "\n",
    "    # Listen für Übersicht des Fortschritts\n",
    "    #R_Score = []\n",
    "    #F_Score = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "\n",
    "    Gen_Opt = t.optim.RMSprop(NN_Generator.parameters(),\n",
    "                              lr=LR)\n",
    "    Dis_Opt = t.optim.RMSprop(NN_Discriminator.parameters(),\n",
    "                              lr=LR)\n",
    "\n",
    "    # Iteration über die Epochen\n",
    "    for epoch in range(0, NUM_EPOCH):\n",
    "\n",
    "        # Iteration über die Bilder\n",
    "        for i, (img_real, _) in enumerate(org_loader):\n",
    "\n",
    "            for _ in range(N_CRTIC):\n",
    "                # Trainieren des Diskrimniators\n",
    "                #d_loss, real_score, fake_score = disc_train(img_real, Dis_Opt)\n",
    "                d_loss = disc_train(img_real, Dis_Opt)\n",
    "\n",
    "                for p in NN_Discriminator.parameters():\n",
    "                    p.data.clamp_(-WEIGHT_CLIPPING, WEIGHT_CLIPPING)\n",
    "\n",
    "            # Trainieren des Generators\n",
    "            g_loss = gen_train(Gen_Opt)\n",
    "\n",
    "            Count = i  # Index/ Iterationen zählen\n",
    "            print(\"index:\", i, \"D_loss:\", d_loss, \"G_Loss:\", g_loss)\n",
    "\n",
    "        # Speichern des Gesamtlosses von D und G und der Real und Fake Scores\n",
    "        D_losses.append(d_loss)\n",
    "        G_losses.append(g_loss)\n",
    "        # R_Score.append(real_score)\n",
    "        # F_Score.append(fake_score)\n",
    "\n",
    "        # Ausgabe EPOCH, Loss: G und D, Scores: Real und Fake\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}\".format(\n",
    "            epoch+1, NUM_EPOCH, g_loss, d_loss))  # , real_score, fake_score))\n",
    "\n",
    "        # Speichern der generierten Samples/ Images\n",
    "        saves_gen_samples(epoch+start_idx, random_Tensor)\n",
    "\n",
    "    return G_losses, D_losses  # , R_Score, F_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc577e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufruf der Trainingsfunktion (Diskriminator & Generator mit der LR & Anzahl der Epochen)\n",
    "G_losses, D_losses = train(NN_Discriminator, NN_Generator, NUM_EPOCH, LR)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "comment_questions,-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
